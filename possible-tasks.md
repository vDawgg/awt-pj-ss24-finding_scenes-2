# Evaluation metrics
## Scene extraction:
- Precision of chapter extraction
  - This should be used together with the vidchapters dataset to see how the naive approach compares to the more advanced approaches and also have an idea on why the method might not be performing well.

# Caption generation
- CIDEr score needs multiple reference sentences to work properly
  - Can be used for evaluating the captions and the 
  - Currently, the score is incredibly bad â†’ might also have to try 
  - Seems like 5 reference sentences is generally good. 3 should be stable enough
- For qualitative eval we might show the metadata for our last/first talk
  - Have captions for this and listeners should already be familiar.

# Datasets for evaluation:
- YouCook2 is used very often but cheating a bit, as the captioning seems to be only built on the subtitles already contained in the YouTube video
- HowTo100m is not available online anymore.
  - Also only uses the actual subtitles from the video.
- The tiniest of Datasets could be self-made by watching shorter instructional videos that have been sequenced by our model and comparing the captioning to our manual captioning.
  - Upside for this would be that we dont have to rewrite the captioning logic because we cant use our own scene extraction.
  - Additional upside is that we could also include other tasks than only captioning.
  - Downside of this is its going to take ages, it is biased and the caption quality is unlikely to be that good.
  - Question here would also be if CIDEr will actually perform that well on likely very differently written output.
    - Instead of this one of the other metrics could be used instead though.
- MSR-VTT seems like a good approach as they use manually captioned videos.
  - Downside here is that the videos in the ds aren't all instructional, which is not the domain we are focusing on but shouldnt really matter for the captioning task.
  - Also we do not have any subtitles available as context
    - This might be the dealbreaker if the original code for downloading the videos is not available anymore
    - 


### To add (generated by LLM):
- general description of the whole video
- academic field (e.g. compsci)
  - could be broadened to general field/video topic if it should be applied to other video types
  - could be combined with intended audience
  - could be combined with difficulty
  - 

### To add (generated by VLM):
- Key concepts in scene
- visual aids/tools used to educate in the scene
- possible questions/interactions in the scene
- text in scene (ocr)

### Maybe add (generated by LLM):
- possible prerequisites for understanding the video

### Maybe add (generated by VLM):
- possible further resources mentioned in video


